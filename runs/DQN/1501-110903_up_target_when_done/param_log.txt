env: CustomEnvSimple(
	Screen_size=(288, 512) (normalized obs: False	Action space: Discrete(2)
	Observation space: Box(-inf, inf, (7,), float32)
	Env obs variables: ['player_x', 'player_y', 'pipe_center_x', 'pipe_center_y', 'v_dist', 'h_dist', 'player_vel_y']
	Env obs values: [ 57. 244. 488. 255.  -1. 477.  -9.]
	Reward range: {'alive': 0.1, 'pass_pipe': 1, 'dead': -1, 'score': 0}
)
n_actions: 2
n_observations: 7
device: mps
EPOCHS: 1500
BATCH_SIZE: 64
LR: 0.0001
MEMORY_SIZE: 100000
GAMMA: 0.99
EPS_START: 0.9
EPS_END: 0.01
EPS_DECAY: 2000
TAU: 0.005
LAYER_SIZES: [64, 128, 256, 256]
policy_net: DQN(
  (layer1): Linear(in_features=7, out_features=64, bias=True)
  (layer2): Linear(in_features=64, out_features=128, bias=True)
  (layer3): Linear(in_features=128, out_features=256, bias=True)
  (layer4): Linear(in_features=256, out_features=256, bias=True)
  (output): Linear(in_features=256, out_features=2, bias=True)
)
target_net: DQN(
  (layer1): Linear(in_features=7, out_features=64, bias=True)
  (layer2): Linear(in_features=64, out_features=128, bias=True)
  (layer3): Linear(in_features=128, out_features=256, bias=True)
  (layer4): Linear(in_features=256, out_features=256, bias=True)
  (output): Linear(in_features=256, out_features=2, bias=True)
)
optimizer: AdamW (
Parameter Group 0
    amsgrad: True
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.01
)
memory: ReplayMemory with capacity 100000 (100000 used elements)
step_done: 143846
eps_threshold: 0.01
writer: <torch.utils.tensorboard.writer.SummaryWriter object at 0x29188abe0>
best_score: 1
best_duration: 174
